#!/usr/bin/env python
# coding: utf-8

import streamlit as st
from streamlit_chat import message
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain
from langchain.document_loaders.pdf import PyPDFLoader
from langchain.vectorstores import FAISS
import tempfile
import os
def main():
    os.environ["OPENAI_API_KEY"] = "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"
    st.set_page_config(
    page_title="pdf_chatbot",    #é¡µé¢æ ‡é¢˜
    page_icon=":rainbow:",        #icon 
    layout="wide",                #é¡µé¢å¸ƒå±€
    initial_sidebar_state="auto"  #ä¾§è¾¹æ 
    )
    if 'first_visit' not in st.session_state:
        st.session_state.first_visit=True
    else:
        st.session_state.first_visit=False
    # åˆå§‹åŒ–å…¨å±€é…ç½®
    if st.session_state.first_visit:
        # '''åœ¨è¿™é‡Œå¯ä»¥å®šä¹‰ä»»æ„å¤šä¸ªå…¨å±€å˜é‡ï¼Œæ–¹ä¾¿ç¨‹åºè¿›è¡Œè°ƒç”¨'''
        # st.session_state.random_city_index=random.choice(range(len(st.session_state.city_mapping)))
        st.balloons()
    user_api_key = st.sidebar.text_input(
        label="#### Your OpenAI API key ğŸ‘‡",
        placeholder="Paste your openAI API key, sk-",
        type="password")
    
    uploaded_file =st.sidebar.file_uploader("upload", type="pdf",accept_multiple_files=False) 
    if uploaded_file :
        with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
            # get temp_file_path
            tmp_file.write(uploaded_file.getvalue())
            tmp_file_path = tmp_file.name
            # load data
            loader = PyPDFLoader(tmp_file_path)
            data = loader.load()

            #use tempfile because PyPDFLoader only accepts a file_path
        
            # è¿™æ˜¯streamlitçš„ç‘å£«å†›åˆ€ï¼Œè¿”å›ä¸ºNone,å¯ä»¥æ ¹æ®è¾“å…¥çš„ä¸åŒäº§ç”Ÿä¸åŒçš„æ•ˆæœ
            st.write(data)

            embeddings = OpenAIEmbeddings()
            vectorstore = FAISS.from_documents(data, embeddings)
            chain = ConversationalRetrievalChain.from_llm(
                llm = ChatOpenAI(temperature=0.0,model_name='gpt-3.5-turbo'),retriever=vectorstore.as_retriever())
        class MyRandom:
            def __init__(self,num):
                self.random_num=num

        def my_hash_func(my_random):
            num = my_random.random_num
            return num 
        
        @st.cache(hash_funcs={MyRandom: my_hash_func})  
        def conversational_chat(query):
            try:
                result = chain({"question": query,"chat_history": st.session_state['history']})
                st.session_state['history'].append((query, result["answer"]))
                
            except Exception as e:
                if 'cannot identify file' in str(e):
                    return conversational_chat(my_random)
                else:
                    st.error(str(e))
            return result["answer"]
        
        if 'history' not in st.session_state:
            st.session_state['history'] = []

        if 'generated' not in st.session_state:
            st.session_state['generated'] = ["Hello ! Ask me anything about " +uploaded_file.name+ "  "]

        if 'past' not in st.session_state:
            st.session_state['past'] = ["Hey ! "]


        #container for the chat history
        response_container = st.container()
        #container for the user's text input
        container = st.container()


        #  UIéƒ¨åˆ†
        # withåé¢å¿…é¡»è·Ÿä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨
        # å¦‚æœä½¿ç”¨äº†asï¼Œåˆ™æ˜¯æŠŠä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„ __enter__() æ–¹æ³•çš„è¿”å›å€¼èµ‹å€¼ç»™ target
        # target å¯ä»¥æ˜¯å•ä¸ªå˜é‡ï¼Œæˆ–è€…ç”±â€œ()â€æ‹¬èµ·æ¥çš„å…ƒç»„ï¼ˆä¸èƒ½æ˜¯ä»…ä»…ç”±â€œ,â€åˆ†éš”çš„å˜é‡åˆ—è¡¨ï¼Œå¿…é¡»åŠ â€œ()â€ï¼‰
        with container:
            with st.form(key='my_form', clear_on_submit=True):

                user_input = st.text_input("Query:", placeholder="Talk about your pdf data here (:", key='input')
                submit_button = st.form_submit_button(label='Send')

            if submit_button and user_input:
                output = conversational_chat(user_input)

                st.session_state['past'].append(user_input)
                st.session_state['generated'].append(output)
                
        if st.session_state['generated']:
                with response_container:
                    for i in range(len(st.session_state['generated'])):
                        message(st.session_state["past"][i], is_user=True, key=str(i) + '_user', avatar_style="big-smile")
                        message(st.session_state["generated"][i], key=str(i), avatar_style="thumbs")


if __name__ == '__main__':
    main()