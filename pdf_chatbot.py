#!/usr/bin/env python
# coding: utf-8

import streamlit as st
from streamlit_chat import message
from langchain.document_loaders.pdf import PyPDFLoader
from langchain.text_splitter import TextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.chains import ConversationalRetrievalChain

from langchain.vectorstores import FAISS
import tempfile
import os

from chunks import load_pdf,split_paragraph

def main():
    
    st.set_page_config(
    page_title="pdf_chatbot",    #é¡µé¢æ ‡é¢˜
    page_icon=":rainbow:",        #icon 
    layout="wide",                #é¡µé¢å¸ƒå±€
    initial_sidebar_state="auto"  #ä¾§è¾¹æ 
    )
    if 'first_visit' not in st.session_state:
        st.session_state.first_visit=True
    else:
        st.session_state.first_visit=False
    # åˆå§‹åŒ–å…¨å±€é…ç½®
    if st.session_state.first_visit:
        # '''åœ¨è¿™é‡Œå¯ä»¥å®šä¹‰ä»»æ„å¤šä¸ªå…¨å±€å˜é‡ï¼Œæ–¹ä¾¿ç¨‹åºè¿›è¡Œè°ƒç”¨'''
        st.balloons()
    user_api_key = st.sidebar.text_input(
        label="#### Your OpenAI API key ğŸ‘‡",
        placeholder="Paste your openAI API key, sk-",
        type="password")
    
    os.environ["OPENAI_API_KEY"] = user_api_key

    uploaded_file =st.sidebar.file_uploader("upload", type="pdf",accept_multiple_files=True) 
    if uploaded_file :
        for singlefile in uploaded_file:
        #use tempfile because PyPDFLoader only accepts a file_path
            with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
                # get temp_file_path
                tmp_file.write(singlefile.getvalue())
                tmp_file_path = tmp_file.name
                # load data
                # loader = PyPDFLoader(tmp_file_path)       
                # data = loader.load()#æ­¤æ—¶çš„è¾“å‡ºä¸ºlist[Documents(,,)]
                # å°†dataä¸­å†…å®¹çš„å­—ç¬¦ä¸²å˜æˆchunks
                # å¦‚ä½•å°†åˆ—è¡¨ä¸­çš„langchainå®šä¹‰çš„Documentç±»å‹çš„ç¬¬ä¸€é¡¹çš„å˜é‡çš„å€¼è¿›è¡Œchunkåˆ’åˆ†
                content=load_pdf(tmp_file_path)
                data=split_paragraph(content,tmp_file_path)
                # è¿™æ˜¯streamlitçš„ç‘å£«å†›åˆ€ï¼Œè¿”å›ä¸ºNone,å¯ä»¥æ ¹æ®è¾“å…¥çš„ä¸åŒäº§ç”Ÿä¸åŒçš„æ•ˆæœ
                st.write(data)
                embeddings = OpenAIEmbeddings()

                vectorstore = FAISS.from_documents(data, embeddings)
                chain = ConversationalRetrievalChain.from_llm(
                    llm = ChatOpenAI(temperature=0.0,model_name='gpt-3.5-turbo'),retriever=vectorstore.as_retriever())
            
        class MyRandom:
            def __init__(self,num):
                self.random_num=num

        def my_hash_func(my_random):
            num = my_random.random_num
            return num 
        
        @st.cache(hash_funcs={MyRandom: my_hash_func})  
        def conversational_chat(query):
            try:
                result = chain({"question": query,"chat_history": st.session_state['history']})
                st.session_state['history'].append((query, result["answer"]))
                
            except Exception as e:
                if 'cannot identify file' in str(e):
                    return conversational_chat(my_random)
                else:
                    st.error(str(e))
            return result["answer"]
        
        if 'history' not in st.session_state:
            st.session_state['history'] = []

        if 'generated' not in st.session_state:
            st.session_state['generated'] = ["Hello ! Ask me anything about " +str([i.name for i in uploaded_file])+ "  "]

        if 'past' not in st.session_state:
            st.session_state['past'] = ["Hey ! "]

        #container for the chat history
        response_container = st.container()
        #container for the user's text input
        container = st.container()

        #  UIéƒ¨åˆ†
        # withåé¢å¿…é¡»è·Ÿä¸€ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨
        # å¦‚æœä½¿ç”¨äº†asï¼Œåˆ™æ˜¯æŠŠä¸Šä¸‹æ–‡ç®¡ç†å™¨çš„ __enter__() æ–¹æ³•çš„è¿”å›å€¼èµ‹å€¼ç»™ target
        # target å¯ä»¥æ˜¯å•ä¸ªå˜é‡ï¼Œæˆ–è€…ç”±â€œ()â€æ‹¬èµ·æ¥çš„å…ƒç»„ï¼ˆä¸èƒ½æ˜¯ä»…ä»…ç”±â€œ,â€åˆ†éš”çš„å˜é‡åˆ—è¡¨ï¼Œå¿…é¡»åŠ â€œ()â€ï¼‰
        with container:
            with st.form(key='my_form', clear_on_submit=True):

                user_input = st.text_input("Query:", placeholder="Talk about your pdf data here (:", key='input')
                submit_button = st.form_submit_button(label='Send')

            if submit_button and user_input:
                output = conversational_chat(user_input)

                st.session_state['past'].append(user_input)
                st.session_state['generated'].append(output)
                
        if st.session_state['generated']:
                with response_container:
                    for i in range(len(st.session_state['generated'])):
                        message(st.session_state["past"][i], is_user=True, key=str(i) + '_user', avatar_style="big-smile")
                        message(st.session_state["generated"][i], key=str(i), avatar_style="thumbs")


if __name__ == '__main__':
    main()